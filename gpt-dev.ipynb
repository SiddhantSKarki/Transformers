{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326a5af7-819a-4474-a9b0-251e7c3a127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-24 22:46:32--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8000::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  6.32MB/s    in 0.2s    \n",
      "\n",
      "2024-09-24 22:46:32 (6.32 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adc0f0e-09e5-4d77-b340-99a62e80e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52aa3d2c-f4f2-4b66-80a0-eb72afca72c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261f77be-ec2c-4ec5-9985-112c1d2d4cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfbe72f3-b387-4c1e-811c-cb59d3789cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: \"\".join([itos[n] for n in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af275ec-9525-4ceb-b23c-e58e517e735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 2, 2, 1, 20, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59]\n",
      "hi!! How are you\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hi!! How are you\"))\n",
    "print(decode([46, 47, 2, 2, 1, 20, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14cee5c-0154-44b4-9263-f3e296d7aac3",
   "metadata": {},
   "source": [
    "# Encoding the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288c39ca-9f2e-434c-bf78-3ba18bf2c0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394])\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f949666-c94d-4b9f-ac44-d5799917cd80",
   "metadata": {},
   "source": [
    "# Training and testing data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebcb269-7fbb-4c2d-af98-58792176c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ebedc-ae5d-49e2-a53f-a9c9227a270f",
   "metadata": {},
   "source": [
    "# While working with transformers we work with chunks of dataset (All of it would be computationally expensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d43e97-ddb4-4a26-a85d-4ecc6dac6c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6edaec5-99e9-464c-8b88-3efc0a803bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_szie = 8\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train if split == \"train\" else val\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "    \n",
    "xb, yb = get_batch(\"train\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6f301fd-c8cc-4eb5-88ed-567c928a2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both in the shape (B,T), idx turns into B,T,C after getting the logits\n",
    "        logits = self.token_embedding_table(idx) # takes, (Batch, Time, Channel)\n",
    "        B, T, C = logits.shape\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for  _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx) # Shape is (B, T, C)\n",
    "            logits = logits[:, -1, :] # Shape is (B, C)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # Shape is (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a57bd57b-4131-4bfc-b9c7-5cebcadc9a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.0364, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc0a318-1bf5-4339-be8b-e54b77cd0605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "l-QYjt'CL?jLDuQcLzy'RIo;'KdhpV\n",
      "vLixa,nswYZwLEPS'ptIZqOZJ$CA$zy-QTkeMk x.gQSFCLg!iW3fO!3DGXAqTsq3pdgq\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0b93560-a139-4351-8392-763eda57a67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "988c0efd-991c-4409-a463-4ac153a5b835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5589075088500977\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb , yb = get_batch(\"train\")\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efad75ee-3beb-4d62-bee2-eafa6b3563b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ong h hasbe pave pirance\n",
      "RDe hicomyonthar's\n",
      "PES:\n",
      "AKEd ith henourzincenonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KINld pe wither vouprroutherccnohathe; d!\n",
      "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so itJas\n",
      "Waketancotha:\n",
      "h hay.JUCLUKn prids, r loncave w hollular s O:\n",
      "HIs; ht anjx\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx, max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f6617-ae0f-4bc9-b0eb-b92a84fc63c5",
   "metadata": {},
   "source": [
    "# The mathemtical trick used in self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c54ae36-52d6-4ed2-a611-5b86b8bc49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "lower_triangular = torch.tril(torch.ones(3,3, dtype=torch.int))\n",
    "lower_triangular = lower_triangular / torch.sum(lower_triangular, 1, keepdim=True)\n",
    "b = torch.randint(10, (3,4)).float()\n",
    "print(lower_triangular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c242d6d0-a472-4b62-8857-f1d62e4d4846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 3., 3.],\n",
      "        [7., 6., 4., 5.],\n",
      "        [3., 7., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e6aa4a0-a880-4d06-921b-cc78bc7c2c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 1.0000, 3.0000, 3.0000],\n",
      "        [4.5000, 3.5000, 3.5000, 4.0000],\n",
      "        [4.0000, 4.6667, 3.6667, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "print(lower_triangular @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52adcf48-a155-4757-9010-95649275338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 4, 8, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f340369-53b7-4e55-9f97-a82b50600a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b64ac07-e592-45ac-8c94-29ba1078981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb2cfc34-503c-4add-a124-605d1c77e39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac88a621-b428-4b3c-a467-c17320ced374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 3.6464e-02, -1.7140e-01],\n",
      "         [ 3.6715e-01, -1.7754e-01],\n",
      "         [-8.7498e-02, -4.3437e-02],\n",
      "         [-3.3560e-01,  1.0641e-01],\n",
      "         [-2.9223e-01,  3.4569e-01],\n",
      "         [-2.6991e-01,  2.1853e-01],\n",
      "         [-2.6965e-01,  7.4588e-02],\n",
      "         [-2.9767e-01,  4.7604e-01]],\n",
      "\n",
      "        [[-1.1187e-01,  1.2848e+00],\n",
      "         [-1.0401e-01,  1.3754e+00],\n",
      "         [ 5.1072e-01,  6.3233e-01],\n",
      "         [ 7.6424e-01,  6.1603e-01],\n",
      "         [ 5.4028e-01,  3.1049e-01],\n",
      "         [ 2.6961e-01,  1.4276e-01],\n",
      "         [ 2.3420e-01,  1.1311e-01],\n",
      "         [-8.2713e-03,  1.3474e-01]],\n",
      "\n",
      "        [[-1.2228e+00,  1.5673e-01],\n",
      "         [-6.2128e-01,  2.6980e-01],\n",
      "         [-2.4584e-01,  9.2436e-01],\n",
      "         [-1.7305e-01,  5.9401e-01],\n",
      "         [-4.4866e-01,  5.4448e-01],\n",
      "         [-3.9372e-01,  7.0349e-01],\n",
      "         [-3.7888e-01,  6.3211e-01],\n",
      "         [-3.0721e-01,  4.0055e-01]],\n",
      "\n",
      "        [[-4.8165e-04, -5.9358e-01],\n",
      "         [-1.2453e-01, -2.0609e-01],\n",
      "         [-5.4084e-01, -2.5497e-02],\n",
      "         [-5.8544e-01,  7.9387e-02],\n",
      "         [-5.2323e-02,  2.9184e-01],\n",
      "         [-3.2682e-01, -2.4351e-02],\n",
      "         [-2.2887e-01, -1.5995e-01],\n",
      "         [-2.5013e-01,  4.7925e-03]]])\n"
     ]
    }
   ],
   "source": [
    "print(xbow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e0f60-8cd2-47da-bf19-7ce8681c71a4",
   "metadata": {},
   "source": [
    "# Version3 : Using Softmax (More interesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a271d9df-0513-4f38-95e1-e581da63646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wei was being applied in the same way to all batch elements\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8176c5f9-9edf-4874-9d7b-e8654cebbed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c808c6-4c25-453e-a081-3bf886e908e1",
   "metadata": {},
   "source": [
    "# Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfef6f32-683c-4cc6-9f67-f4884f2571aa",
   "metadata": {},
   "source": [
    "Key point: \n",
    "\n",
    "x is sort of like a private information here. \n",
    "For example: say for the 5th token, it has its vector with some information associate about it (position + token emb). Given this information, if you find me interseting, here's what I want to communicate (stored in v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2396e3cc-e29e-4e6c-94e8-3f09d37b801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "\n",
    "out = wei @ v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3423f-e7e1-462c-a614-c51ea754c541",
   "metadata": {},
   "source": [
    "# Raw affinities for all the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d833e06f-7fbd-476f-8291-4f997df613cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ed024-d805-4527-a81a-19a06ff1a2f3",
   "metadata": {},
   "source": [
    "# If I'm a fifth node I would not want to aggrigate any thing above 5th (6, 7, 8 etc). So we need to convert it to the lower triangular form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e03c14c-177b-4688-8364-f1eb14711d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., -inf, -inf, -inf, -inf, -inf, -inf, -inf])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n",
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e272608-d043-4c85-a0b1-500c73c23f22",
   "metadata": {},
   "source": [
    "# Now we expontiate and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec800d0d-48ad-4e11-8c3f-fe702029c4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = F.softmax(wei, dim=-1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408eb897-ebce-4018-ad3a-3f42958d5877",
   "metadata": {},
   "source": [
    "Say we're doing sentiment analysis, you would want all nodes to communicate with each other, in that case instead of a lower triangular matrix, you would use the full matrix (In lower triangular information can only flow in the past, not in the future), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa454f-8b53-4f7f-9a26-610f141cc636",
   "metadata": {},
   "source": [
    "Node:\n",
    "1) Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregrating information\n",
    "   with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "2) There is no notion of space. Attention simply acts over a set of vectors. This is why we need to postionally encode tokens.\n",
    "3) Each example across batch dimention is of course processed completely independently and never \"talk\" each other.\n",
    "4) In a \"encoder\" attention block just delete the single line that does masking with ```tril```, allowing all tokens to communicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381aea0-fd2c-40df-aef5-127cb03024d0",
   "metadata": {},
   "source": [
    "# Self attention: Same source x produces the keys, queries, and value. Every single node with emit 2 vectors, query (what am I loking for?), key (What do I contain), if they're aligned they have a high amount\n",
    "# Cross Attention: Sometimes the keys come from a separate source "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16efe2-41bb-4b72-935a-f9bf3e9879f9",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "- \"Scaled\" attention addiitonally divides ```wei``` by $1/{sqrt(head_size)}$. This makes it so which input $Q,K$ are unit variance, wei will be in unit variance too and Softmax will stay diffuse and not saturate too much. Illustration Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b808de1a-915a-4f38-ad67-a53bd3b18acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B, T, head_size)\n",
    "q = torch.randn(B, T, head_size)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "306b75db-47fe-47a9-aa13-f3bd93946b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48062b98-6876-4bc6-8407-0e7f71d3e56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97291743-8847-4ceb-bf8e-0918494527ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb8db6-229a-4114-9ec7-abfbda3882b0",
   "metadata": {},
   "source": [
    "# Because of softmax (Gives us diffused forms), if wei takes a very positive or very negative numbers inside it, softmax starts to converge the vectors into one-hot. If the wei values are too extreme, softmax will be very peaky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2bb1c6-00b0-41b5-a06b-90e0b699125a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebed0602-5da2-4e4d-b3d3-02f38328d826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
